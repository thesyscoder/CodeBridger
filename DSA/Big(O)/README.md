# Big O Notation

”Big O” notation, officially known as O-notation, is used in computer science to describe the performance or complexity of an algorithm. Specifically, it provides an upper bound on the time complexity, describing the worst-case scenario.

## Big O and scalability

**Big O Notation:**
Big O notation is a mathematical notation used in computer science to describe the time complexity or space complexity of an algorithm in terms of its input size. It represents the upper bound of the algorithm's growth rate.

**Scalability:**
Scalability refers to the ability of a system, network, or process to handle a growing amount of work or resources in a graceful manner, typically without requiring significant changes to the underlying structure or architecture. It often involves maintaining performance, reliability, and efficiency as the system expands.

## Time and Space complexity

**Time Complexity:** The time it takes for an algorithm to run, in terms of the size of the input. It is usually expressed using the "O" notation.

**Space Complexity:** The space required by an algorithm to execute. This is typically measured in terms of the number of primary memory.
